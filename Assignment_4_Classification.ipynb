{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a87fea-a159-49ea-a305-ffd299fa8bb1",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 46px; color: blue;\">\n",
    "    <u><b>ASSIGNMENT 4 - CLASSIFICATION</b></u>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bdc189-45c0-4d6c-9cf6-4fc36fa2af1e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: LEFT; font-size: 20px; color: white;\">\n",
    "    <p>The dataset \"Breast Cancer\" contains various features related to cell measurements, including characteristics such as radius, texture, smoothness, and compactness, along with a target variable indicating whether the tumor is malignant or benign. The primary goal of this project is to design and implement a comprehensive classification system that addresses key challenges in classifying tumors, such as feature scaling, model selection, and handling class imbalance. By applying effective classification algorithms, the objective is to analyze and predict whether a tumor is malignant or benign based on the provided features, ultimately enhancing the overall quality, reliability, and usability of the model for further analysis and machine learning applications. This task will focus on implementing and comparing multiple classification techniques to determine the best model for tumor classification. </p>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab3617a-590f-48b8-be86-c58d354764ec",
   "metadata": {},
   "source": [
    "<div style=\"text-align: LEFT; font-size: 20px; color: red;\">\n",
    "    <u><b>SOURCE</b></u>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6f1377-2d7a-427b-8c14-b8b0eebdda92",
   "metadata": {},
   "source": [
    "<div style=\"text-align: LEFT; font-size: 20px; color: white;\">\n",
    "    <p>The Breast Cancer dataset used for this project is available in the sklearn library. It can be loaded using the `load_breast_cancer()` function from `sklearn.datasets`.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a21ca6-a09a-4a89-889f-4d7c93da3f33",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 36px; color: red;\">\n",
    "    <u><b>IMPORTING MODULES</b></u>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e10b34-f64f-49a5-bacd-7c465171b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ee246-b327-4635-964c-d1d91d21d228",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 36px; color: red;\">\n",
    "    <u><b>LOADING & PREPROCESSING</b></u>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b9b74-d5cf-411a-a2b6-ed3e7f79ab85",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>1. LOAD THE DATA AND CONVERT INTO DATA FRAME</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc93b83d-3ff7-46ec-8bfe-7900b66c55c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.07871  ...          17.33           184.60      2019.0   \n",
      "1                 0.05667  ...          23.41           158.80      1956.0   \n",
      "2                 0.05999  ...          25.53           152.50      1709.0   \n",
      "3                 0.09744  ...          26.50            98.87       567.7   \n",
      "4                 0.05883  ...          16.67           152.20      1575.0   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  target  \n",
      "0          0.4601                  0.11890       0  \n",
      "1          0.2750                  0.08902       0  \n",
      "2          0.3613                  0.08758       0  \n",
      "3          0.6638                  0.17300       0  \n",
      "4          0.2364                  0.07678       0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# LOAD THE DATASET\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Convert to DataFrame \n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72980424-255b-403b-9b16-01603c36b40b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>2. DISPLAY FIRST & LAST ROWS</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fa7762c-026e-4239-b502-c39db5b20f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.07871  ...          17.33           184.60      2019.0   \n",
      "1                 0.05667  ...          23.41           158.80      1956.0   \n",
      "2                 0.05999  ...          25.53           152.50      1709.0   \n",
      "3                 0.09744  ...          26.50            98.87       567.7   \n",
      "4                 0.05883  ...          16.67           152.20      1575.0   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  target  \n",
      "0          0.4601                  0.11890       0  \n",
      "1          0.2750                  0.08902       0  \n",
      "2          0.3613                  0.08758       0  \n",
      "3          0.6638                  0.17300       0  \n",
      "4          0.2364                  0.07678       0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# DISPLAY FIRST FEW ROWS TO UNDERSTAND THE STRUCTURE OF THE DATA\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43dd28ff-c0ed-4058-ba5a-e3183f879ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "564                 0.05623  ...          26.40           166.10      2027.0   \n",
      "565                 0.05533  ...          38.25           155.00      1731.0   \n",
      "566                 0.05648  ...          34.12           126.70      1124.0   \n",
      "567                 0.07016  ...          39.42           184.60      1821.0   \n",
      "568                 0.05884  ...          30.37            59.16       268.6   \n",
      "\n",
      "     worst smoothness  worst compactness  worst concavity  \\\n",
      "564           0.14100            0.21130           0.4107   \n",
      "565           0.11660            0.19220           0.3215   \n",
      "566           0.11390            0.30940           0.3403   \n",
      "567           0.16500            0.86810           0.9387   \n",
      "568           0.08996            0.06444           0.0000   \n",
      "\n",
      "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
      "564                0.2216          0.2060                  0.07115       0  \n",
      "565                0.1628          0.2572                  0.06637       0  \n",
      "566                0.1418          0.2218                  0.07820       0  \n",
      "567                0.2650          0.4087                  0.12400       0  \n",
      "568                0.0000          0.2871                  0.07039       1  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# DISPLAY LAST FEW ROWS TO UNDERSTAND THE STRUCTURE OF THE DATA\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f5b9f6-ce26-4490-b128-3b4e970a9214",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>3. DATATYPE OF EACH COLUMN</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "644e112e-6aaf-4546-a3de-f7c7281a78c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    int32  \n",
      "dtypes: float64(30), int32(1)\n",
      "memory usage: 135.7 KB\n"
     ]
    }
   ],
   "source": [
    "# DISPLAY DATA TYPE OF EACH COLUMN\n",
    "print(\"Dataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982a444-9add-48c9-999d-d3513a698ea1",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>4. STATISTICAL SUMMARY OF DATA</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae162b83-2756-42e9-a772-459b0527e74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension      target  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DISPLAY STATISTICAL SUMMARY \n",
    "print(\"Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038525ae-17b8-4384-ba38-a1117e075d26",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>5. DISPLAY ALL COLUMN NAMES</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2eda4db-3c5d-47cb-8598-6d831bb9bc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DISPLAY PARTICULAR COLUMN\n",
    "print(\"Columns of the dataset:\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814cc95e-5930-486c-90df-516222449254",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>6. NULL / MISSING VALUES IN EACH COLUMN</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57d39e75-bdde-4b04-9db5-ee52ae3c583d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in each column:\n",
      "mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "target                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# DISPLAY NULL VALUES IN EACH COLUMN\n",
    "print(\"Null values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a1db7-6ded-4031-abda-d5e3968b62ea",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>7. DUPLICATE VALUES</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fca0586a-343e-4d10-8746-f6ccbb34f907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FINDING THE TOTAL NO OF DUPLICATES\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e971bd-251d-4676-a3d0-f716a2b298fa",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>8. FEATURE SCALING</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fadf12dd-7e7a-490a-9ec0-c43c14779a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled Feature Data (First 5 rows):\n",
      "[[ 1.09706398e+00 -2.07333501e+00  1.26993369e+00  9.84374905e-01\n",
      "   1.56846633e+00  3.28351467e+00  2.65287398e+00  2.53247522e+00\n",
      "   2.21751501e+00  2.25574689e+00  2.48973393e+00 -5.65265059e-01\n",
      "   2.83303087e+00  2.48757756e+00 -2.14001647e-01  1.31686157e+00\n",
      "   7.24026158e-01  6.60819941e-01  1.14875667e+00  9.07083081e-01\n",
      "   1.88668963e+00 -1.35929347e+00  2.30360062e+00  2.00123749e+00\n",
      "   1.30768627e+00  2.61666502e+00  2.10952635e+00  2.29607613e+00\n",
      "   2.75062224e+00  1.93701461e+00]\n",
      " [ 1.82982061e+00 -3.53632408e-01  1.68595471e+00  1.90870825e+00\n",
      "  -8.26962447e-01 -4.87071673e-01 -2.38458552e-02  5.48144156e-01\n",
      "   1.39236330e-03 -8.68652457e-01  4.99254601e-01 -8.76243603e-01\n",
      "   2.63326966e-01  7.42401948e-01 -6.05350847e-01 -6.92926270e-01\n",
      "  -4.40780058e-01  2.60162067e-01 -8.05450380e-01 -9.94437403e-02\n",
      "   1.80592744e+00 -3.69203222e-01  1.53512599e+00  1.89048899e+00\n",
      "  -3.75611957e-01 -4.30444219e-01 -1.46748968e-01  1.08708430e+00\n",
      "  -2.43889668e-01  2.81189987e-01]\n",
      " [ 1.57988811e+00  4.56186952e-01  1.56650313e+00  1.55888363e+00\n",
      "   9.42210440e-01  1.05292554e+00  1.36347845e+00  2.03723076e+00\n",
      "   9.39684817e-01 -3.98007910e-01  1.22867595e+00 -7.80083377e-01\n",
      "   8.50928301e-01  1.18133606e+00 -2.97005012e-01  8.14973504e-01\n",
      "   2.13076435e-01  1.42482747e+00  2.37035535e-01  2.93559404e-01\n",
      "   1.51187025e+00 -2.39743838e-02  1.34747521e+00  1.45628455e+00\n",
      "   5.27407405e-01  1.08293217e+00  8.54973944e-01  1.95500035e+00\n",
      "   1.15225500e+00  2.01391209e-01]\n",
      " [-7.68909287e-01  2.53732112e-01 -5.92687167e-01 -7.64463792e-01\n",
      "   3.28355348e+00  3.40290899e+00  1.91589718e+00  1.45170736e+00\n",
      "   2.86738293e+00  4.91091929e+00  3.26373441e-01 -1.10409044e-01\n",
      "   2.86593405e-01 -2.88378148e-01  6.89701660e-01  2.74428041e+00\n",
      "   8.19518384e-01  1.11500701e+00  4.73268037e+00  2.04751088e+00\n",
      "  -2.81464464e-01  1.33984094e-01 -2.49939304e-01 -5.50021228e-01\n",
      "   3.39427470e+00  3.89339743e+00  1.98958826e+00  2.17578601e+00\n",
      "   6.04604135e+00  4.93501034e+00]\n",
      " [ 1.75029663e+00 -1.15181643e+00  1.77657315e+00  1.82622928e+00\n",
      "   2.80371830e-01  5.39340452e-01  1.37101143e+00  1.42849277e+00\n",
      "  -9.56046689e-03 -5.62449981e-01  1.27054278e+00 -7.90243702e-01\n",
      "   1.27318941e+00  1.19035676e+00  1.48306716e+00 -4.85198799e-02\n",
      "   8.28470780e-01  1.14420474e+00 -3.61092272e-01  4.99328134e-01\n",
      "   1.29857524e+00 -1.46677038e+00  1.33853946e+00  1.22072425e+00\n",
      "   2.20556166e-01 -3.13394511e-01  6.13178758e-01  7.29259257e-01\n",
      "  -8.68352984e-01 -3.97099619e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = df.drop(columns=['target'])  \n",
    "y = df['target'] \n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"\\nScaled Feature Data (First 5 rows):\")\n",
    "print(X_scaled[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda8983-fd71-41a6-bbde-6cf6c83398f4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>9. SPLITTING THE DATA INTO TRAINING AND TESTING SET</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "287b436f-b79a-4d41-89e0-92dd03afc51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (398, 30)\n",
      "Testing data shape: (171, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Display the shape of the split data\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e7723-0e51-4708-b7ec-b1667b73a8bd",
   "metadata": {},
   "source": [
    "<div style=\"text-align: LEFT; font-size: 20px; color: white;\">\n",
    "    <p><b><u>Preprocessing steps with explanations:</u></b>\n",
    "\n",
    "1. *Load the Data*: \n",
    "   - The dataset is loaded using load_breast_cancer() from sklearn.datasets. This gives us the feature data (X) and the target data (y), which indicates whether a tumor is malignant (1) or benign (0).\n",
    "\n",
    "2. *Convert to DataFrame*: \n",
    "   - Converted the data into pandas DataFrames for easier manipulation and analysis.\n",
    "\n",
    "3. *Display First and Last Rows*: \n",
    "   - Displayed the first few rows to understand the data structure and confirm it loaded correctly.\n",
    "\n",
    "4. *Check Data Types*: \n",
    "   - Used `info()` to check the data types of the columns and ensure they are as expected (numerical values).\n",
    "\n",
    "5. *Statistical Summary*: \n",
    "   - Used `describe()` to view statistics (mean, min, max, etc.) of both features and target to understand their distribution.\n",
    "\n",
    "6. *Display Column Names*: \n",
    "   - Printed the column names of the features to know what variables we are working with.\n",
    "\n",
    "7. *Check for Missing Values*: \n",
    "   - Checked for missing values with `isnull().sum()` to ensure the dataset is complete.\n",
    "\n",
    "8. *Find Duplicate Rows*: \n",
    "   - Checked for duplicate rows using `duplicated().sum()` to ensure there are no repeated records.\n",
    "\n",
    "9. *Feature Scaling*: \n",
    "   - Scaled the features using `StandardScaler` to ensure that all features are on the same scale, which is important for some machine learning models.\n",
    "\n",
    "10. *Train-Test Split*: \n",
    "    - Split the data into training and testing sets to evaluate the model’s performance on unseen data.\n",
    "\n",
    "These steps are necessary to clean and prepare the data for better model performance.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a0bb1e-245c-467d-9da8-ce5e08b9006a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 36px; color: red;\">\n",
    "    <u><b>CLASSIFICATION ALGORITHMS IMPLEMENTATION</b></u>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f128f655-beb0-454a-9170-e3fdf1b3277e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>1. LOGISTIC REGRESSION ALGORITHM</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22cf0c4d-19a0-49f7-8311-a89bd8243473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6dad2d-60be-4f51-8607-8efe8309d84d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 22px; color: white;\">\n",
    "    <p>Logistic Regression works by estimating the probability of a binary outcome based on input features, using a logistic function. It assumes a linear relationship between the features and the target variable. This model is suitable for the Breast Cancer dataset because factors like cell characteristics likely have a linear influence on the likelihood of a tumor being malignant or benign, making it an appropriate choice for classifying tumor types.</p>\n",
    " </div>       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9531c7-fde0-4de2-9114-ab8b29119fe4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>2. DECISION TREE CLASSIFIER ALGORITHM</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a47baff2-e15a-4fd5-a851-571a76cbea29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "y_pred_dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da67223a-1dce-4677-b9eb-20a6e9a32313",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 22px; color: white;\">\n",
    "    <p>The Decision Tree Classifier works by recursively splitting the data based on feature values to maximize information gain and minimize impurity within each subset. It does not assume a linear relationship between the target variable and the input features. This model is suitable for the Breast Cancer dataset because it can capture non-linear relationships and complex interactions between features, such as how various cell characteristics might jointly influence the likelihood of a tumor being malignant or benign in ways that a linear model cannot.</P>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d2a1f-1840-45c8-9c44-2c9071a020e3",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>3. RANDOM FOREST CLASSIFIER ALGORITHM</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d0ba660-8dd3-41e8-b236-4ada99e20fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e7677-6256-4aae-a576-77cd01a0b204",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 22px; color: white;\">\n",
    "    <p>The Random Forest Classifier is an ensemble learning method that constructs multiple decision trees and combines their predictions to enhance accuracy and reduce overfitting. It effectively handles complex, non-linear relationships between features and the target variable. This makes it suitable for the Breast Cancer dataset, as it can capture intricate interactions between factors like cell radius, texture, smoothness, and compactness, while providing robust predictions and insights into feature importance for classifying tumors as malignant or benign.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2744a11-4bdf-4424-a67c-4479c440b42f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>4. K NEAREST NEIGHBOUR CLASSIFIER ALGORITHM</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "30adc0bb-ed1c-4bd2-ad38-540dee23728d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "y_pred_knn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a9368-aa99-4c55-a33f-5cd46b8077cf",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 22px; color: white;\">\n",
    "    <p>The k-Nearest Neighbors (k-NN) Classifier is a simple, instance-based learning algorithm that classifies data points based on the majority class of their nearest neighbors. It computes the distance between the input data and other points in the feature space to make predictions. This method is well-suited for the Breast Cancer dataset as it can effectively capture complex, non-linear relationships between features like cell radius, texture, and smoothness, which are important for classifying tumors as malignant or benign. The flexibility of k-NN to handle varied data patterns makes it a robust choice for classification tasks in this dataset.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0695a6-8dab-4094-a79e-8d1c35042604",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>5. SUPPORT VECTOR CLASSIFIER ALGORITHM</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5bf12bd0-3aad-4715-92bb-ebbe53a6b183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(kernel='linear')  \n",
    "\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svc = svc_model.predict(X_test)\n",
    "y_pred_svc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28751a1a-3afd-4cca-987a-3d437793bd1d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 22px; color: white;\">\n",
    "    <p>The Support Vector Classifier (SVC) is a classification model that finds a hyperplane that best separates the data into different classes, focusing on maximizing the margin between data points of different classes. It can handle both linear and non-linear decision boundaries by applying kernel functions, such as the Radial Basis Function (RBF). SVC is suitable for the Breast Cancer dataset because it can effectively capture complex, non-linear relationships between features like cell texture, radius, and smoothness, while also being robust to outliers and effective in high-dimensional spaces.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ec8e5-e978-44ed-a13e-6998aea03d24",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 36px; color: red;\">\n",
    "    <u><b>MODEL EVALUATION</b></u>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52121426-84e7-49c6-b63e-cf1a7ebcf61a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>1. LOGISTIC REGRESSION MODEL EVALUATION</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f3dd4ffa-b9e2-4fbc-8a4a-3ae2f964bf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 98.25%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 62   1]\n",
      " [  2 106]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98        63\n",
      "           1       0.99      0.98      0.99       108\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.98      0.98      0.98       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff36969-6336-4613-9546-c4750d2130ac",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>2. DECISION TREE CLASSIFIER MODEL EVALUATION</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9d5a122-1234-48f5-a118-be92468bedf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Accuracy: 92.98%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[60  3]\n",
      " [ 9 99]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        63\n",
      "           1       0.97      0.92      0.94       108\n",
      "\n",
      "    accuracy                           0.93       171\n",
      "   macro avg       0.92      0.93      0.93       171\n",
      "weighted avg       0.93      0.93      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_dtc = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree Classifier Accuracy: {accuracy_dtc * 100:.2f}%\")\n",
    "\n",
    "#  Confusion Matrix\n",
    "cm_dtc = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_dtc)\n",
    "\n",
    "# Classification Report\n",
    "report_dtc = classification_report(y_test, y_pred_dt)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report_dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e4034a-e870-49a1-8599-a73adad9104b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>3. RANDOM FOREST CLASSIFIER MODEL EVALUATION</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e0c335e3-1d83-4e9b-84fd-aa24d872aa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 97.08%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 59   4]\n",
      " [  1 107]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96        63\n",
      "           1       0.96      0.99      0.98       108\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.96      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_rfc = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Classifier Accuracy: {accuracy_rfc * 100:.2f}%\")\n",
    "\n",
    "#  Confusion Matrix\n",
    "cm_rfc = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_rfc)\n",
    "\n",
    "# Classification Report\n",
    "report_rfc = classification_report(y_test, y_pred_rf)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23aecb6-7229-472b-8729-7c95563895ee",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>4. K NEAREST NEIGHBOUR CLASSIFIER MODEL EVALUATION</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b905eaf1-ba70-4652-8765-cc7093265140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Accuracy: 95.91%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 59   4]\n",
      " [  3 105]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94        63\n",
      "           1       0.96      0.97      0.97       108\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.95      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"KNN Classifier Accuracy: {accuracy_knn * 100:.2f}%\")\n",
    "\n",
    "#  Confusion Matrix\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_knn)\n",
    "\n",
    "# Classification Report\n",
    "report_knn = classification_report(y_test, y_pred_knn)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c46990-e26a-4e6b-87b4-31be3c2c333e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 24px; color: violet;\">\n",
    "    <b>5. SUPPORT VECTOR CLASSIFIER MODEL EVALUATION</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "df97a00c-bd30-4282-8bed-da3b618bf5b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Accuracy: 97.66%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 61   2]\n",
      " [  2 106]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        63\n",
      "           1       0.98      0.98      0.98       108\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.97      0.97      0.97       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "print(f\"Support Vector Classifier Accuracy: {accuracy_svc * 100:.2f}%\")\n",
    "\n",
    "#  Confusion Matrix\n",
    "cm_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_svc)\n",
    "\n",
    "# Classification Report\n",
    "report_svc = classification_report(y_test, y_pred_svc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af113b-af37-4464-b866-1fa50171850d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 28px; color: purple;\">\n",
    "    <b>Summary of Best and Worst-Performing Models</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dcc325-4a40-4149-a995-5c3710522fac",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 22px; color: white;\">\n",
    "    <p><u>Best-Performing Model:</u></p>\n",
    "\n",
    "<P>The Logistic Regression model is the best-performing model, achieving the highest accuracy at 98.25%, and demonstrating the best balance in F1-scores across both classes. This highlights its ability to make the most accurate predictions while effectively capturing the underlying patterns in the data.</P>\n",
    "\n",
    "<P><u>Worst-Performing Model:</u></P>\n",
    "\n",
    "<P>The Decision Tree Classifier performs the worst among the models tested, with the lowest accuracy (92.98%) and relatively lower F1-scores, particularly for class 0. While it performs decently for class 1, its overall accuracy and precision/recall balance are weaker compared to the other models.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e637817-6499-4304-b982-41fd46c4c994",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 36px; color: red;\">\n",
    "    <u><b>CONCLUSION </b></u>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa6bc8c-48aa-4877-a51d-934fb8b1ea50",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-size: 22px; color: white;\">\n",
    "    <p>\n",
    "The Logistic Regression model is the best model for the Breast Cancer dataset, as it delivers strong performance by effectively capturing the underlying patterns in the data. In contrast, the Decision Tree Classifier is the least effective model, likely due to its tendency to overfit and its limited ability to generalize complex relationships between the features.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6002bda-1019-4e59-aa86-03b80ac967b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
